
configfile: os.path.join('configs', 'config_template.yaml')
report: "report.rst"

import sys
utils_path = os.path.join('..', 'scripts')
sys.path.append(os.path.join(os.getcwd(), '..'))
sys.path.append(utils_path)

from settings import output_path
from utils import parse_plot_channels

STAGE_NAME = config["STAGE_NAME"]
STAGE_OUTPUT = config["STAGE_OUTPUT"]
PROFILE = config["PROFILE"]
NEO_FORMAT = config["NEO_FORMAT"]
USE_LINK_AS_STAGE_OUTPUT = config["USE_LINK_AS_STAGE_OUTPUT"]
ADD_UTILS = f"export PYTHONPATH='$PYTHONPATH:{utils_path}'"
OUTPUT_DIR = os.path.join(output_path, PROFILE, STAGE_NAME)

if 'STAGE_INPUT' in config and config['STAGE_INPUT'] is not None:
    STAGE_INPUT = config["STAGE_INPUT"]
else:
    STAGE_INPUT = os.path.join(output_path, PROFILE, 'stage03_trigger_detection',
                               'trigger_times.nix')

PLOT_TSTART = config["PLOT_TSTART"]
PLOT_TSTOP = config["PLOT_TSTOP"]
PLOT_CHANNELS = parse_plot_channels(config["PLOT_CHANNELS"], STAGE_INPUT)
PLOT_FORMAT = config["PLOT_FORMAT"]


if config["DETECTION_BLOCK"] == "WaveHunt_Clustering":
    BLOCK_ORDER = ["clustering", "optical_flow", "critical_points", "critical_points_clustering", "merge_wave_definitions"]

elif config["DETECTION_BLOCK"] == "WaveHunt_Time":
    #BLOCK_ORDER = ["UpTrans_Detector", "Optimal_MAX_ABS_TIMELAG", "MAX_IWI_Search", "WaveHuntTimes_UnicityPrinciple", "WaveHuntTimes_Globality"]
    BLOCK_ORDER = ["UpTrans_Detector", "Optimal_MAX_ABS_TIMELAG", "MAX_IWI_Search", "WaveHuntTimes_UnicityPrinciple", "WaveHuntTimes_Globality"]

METRIC = config["METRIC"]
TIME_SPACE_RATIO = config["TIME_SPACE_RATIO"]
NEIGHBOUR_DISTANCE = config["NEIGHBOUR_DISTANCE"]
MIN_SAMPLES_PER_WAVE = config["MIN_SAMPLES_PER_WAVE"]

ALPHA = config["ALPHA"]
MAX_NITER = config["MAX_NITER"]
CONVERGENCE_LIMIT = config["CONVERGENCE_LIMIT"]
GAUSSIAN_SIGMA = config["GAUSSIAN_SIGMA"]
DERIVATIVE_FILTER = config["DERIVATIVE_FILTER"]
DETECT_CRITICAL_POINTS = config["DETECT_CRITICAL_POINTS"]



MAX_ABS_TIMELAG = config["MAX_ABS_TIMELAG"]
ACCEPTABLE_REJECTION_RATE = config["ACCEPTABLE_REJECTION_RATE"]
MIN_CH_NUM = config["MIN_CH_NUM"]

#### Housekeeping ####

#### Housekeeping ####

wildcard_constraints:
    rule_name = '\w+'

def locate(str_list, string):
    print(str_list)
    print(string)
    if string in str_list:
        return [i for i, el in enumerate(str_list) if el == string][0]
    else:
        raise ValueError("Can't find rule '{}'! Please check the spelling \
                          and the config file.".format(string))

def input_file(wildcards):
    if hasattr(wildcards, 'rule_name'):
        idx = locate(BLOCK_ORDER, wildcards.rule_name)
        if idx:
            return os.path.join(OUTPUT_DIR, BLOCK_ORDER[idx-1],
                                BLOCK_ORDER[idx-1]+'.'+NEO_FORMAT)
    elif len(BLOCK_ORDER):
        return os.path.join(OUTPUT_DIR, BLOCK_ORDER[-1],
                            BLOCK_ORDER[-1]+'.'+NEO_FORMAT)
    return os.path.join(STAGE_INPUT)


rule all:
    input:
        check = os.path.join(OUTPUT_DIR, 'input.check'),
        data = input_file,
        configfile = os.path.join('configs', f'config_{PROFILE}.yaml')
    params:
        command = 'ln -s' if USE_LINK_AS_STAGE_OUTPUT else 'cp'
    output:
        data = os.path.join(OUTPUT_DIR, STAGE_OUTPUT)
    shell:
        """
        {ADD_UTILS}
        {params.command} "{input.data}" "{output.data}"
        """

rule check_input:
    input:
        data = STAGE_INPUT,
        script = os.path.join('scripts', 'check_input.py')
    output:
        temp(os.path.join('{dir}', 'input.check'))
    shell:
        """
        {ADD_UTILS}
        python {input.script} --data "{input.data}"
        touch "{output}"
        """

#### Wave Definitions ####

rule UpTrans_Detector:
    input:
        data = input_file,
        script = os.path.join('scripts', 'UpTrans_Detector.py'),
    output:
        data = os.path.join('{dir}', 'UpTrans_Detector',
                            '{rule_name}.'+NEO_FORMAT),
    shell:
        """
        {ADD_UTILS}
        python {input.script} --data "{input.data}" \
                              --output "{output.data}"
        """

rule Optimal_MAX_ABS_TIMELAG:
    input:
        data = input_file,
        script = os.path.join('scripts', 'Optimal_MAX_ABS_TIMELAG.py'),
    params:
        Max_Abs_Timelag = MAX_ABS_TIMELAG
    output:
        data = os.path.join('{dir}', 'Optimal_MAX_ABS_TIMELAG',
                            '{rule_name}.'+NEO_FORMAT),
    shell:
        """
        {ADD_UTILS}
        python {input.script} --data "{input.data}" \
                              --output "{output.data}" \
                              --Max_Abs_Timelag {params.Max_Abs_Timelag}
        """


rule MAX_IWI_Search:
    input:
        data = input_file,
        script = os.path.join('scripts', 'MAX_IWI_Search.py'),
    params:
        UpTransition = os.path.join('{dir}', 'UpTrans_Detector',
                            'UpTrans_Detector.'+NEO_FORMAT),
        Acceptable_rejection_rate = ACCEPTABLE_REJECTION_RATE,
    output:
        data = os.path.join('{dir}', 'MAX_IWI_Search',
                            '{rule_name}.'+NEO_FORMAT),
    shell:
        """
        {ADD_UTILS}
        python {input.script} --data "{input.data}" \
                              --output "{output.data}" \
                              --UpTransition {params.UpTransition} \
                              --Acceptable_rejection_rate {params.Acceptable_rejection_rate}
        """

rule WaveHuntTimes_UnicityPrinciple:
    input:
        data = input_file,
        script = os.path.join('scripts', 'WaveHuntTimes_UnicityPrinciple.py'),
    params:
        UpTransition = os.path.join('{dir}', 'UpTrans_Detector',
                            'UpTrans_Detector.'+NEO_FORMAT),
    output:
        data = os.path.join('{dir}', 'WaveHuntTimes_UnicityPrinciple',
                            '{rule_name}.'+NEO_FORMAT),
    shell:
        """
        {ADD_UTILS}
        python {input.script} --data "{input.data}" \
                              --output "{output.data}" \
                              --UpTransition {params.UpTransition}
        """

rule WaveHuntTimes_Globality:
    input:
        data = input_file,
        script = os.path.join('scripts', 'WaveHuntTimes_Globality.py'),
    params:
        UpTransition = os.path.join('{dir}', 'UpTrans_Detector',
                            'UpTrans_Detector.'+NEO_FORMAT),
        min_ch_num = MIN_CH_NUM,
    output:
        data = os.path.join('{dir}', 'WaveHuntTimes_Globality',
                            '{rule_name}.'+NEO_FORMAT),
    shell:
        """
        {ADD_UTILS}
        python {input.script} --data "{input.data}" \
                              --output "{output.data}" \
                              --UpTransition {params.UpTransition} \
                              --min_ch_num {params.min_ch_num}

        """



rule clustering:
    input:
        data =     input_file,
        script = os.path.join('scripts', 'clustering.py'),
        plot_script = os.path.join('scripts', 'plot_clustering.py')
    params:
        metric = METRIC,
        time_space_ratio = TIME_SPACE_RATIO,
        neighbour_distance = NEIGHBOUR_DISTANCE,
        min_samples = MIN_SAMPLES_PER_WAVE,
        plot_time_slice = 10
    output:
        data = os.path.join('{dir}', 'clustering',
                            '{rule_name}.'+NEO_FORMAT),
        img = report(os.path.join('{dir}', '{rule_name}',
                                  'wave_clustering.'+PLOT_FORMAT)),
    shell:
        """
        {ADD_UTILS}
        python {input.script} --data "{input.data}" \
                              --output "{output.data}" \
                              --metric {params.metric} \
                              --time_space_ratio {params.time_space_ratio} \
                              --neighbour_distance {params.neighbour_distance} \
                              --min_samples {params.min_samples}
        python {input.plot_script} --data "{output.data}" \
                                   --output "{output.img}" \
                                   --time_slice {params.plot_time_slice}
        """


rule optical_flow:
    input:
        data = STAGE_INPUT,
        script = os.path.join('scripts', 'horn_schunck.py')
    params:
        alpha = ALPHA,
        max_Niter = MAX_NITER,
        convergence_limit = CONVERGENCE_LIMIT,
        gaussian_sigma = GAUSSIAN_SIGMA,
        derivative_filter = DERIVATIVE_FILTER
    output:
        data = os.path.join('{dir}', 'optical_flow',
                            '{rule_name}.'+NEO_FORMAT),
        img = report(os.path.join('{dir}', '{rule_name}',
                                  'optical_flow.'+PLOT_FORMAT)),
    shell:
        """
        {ADD_UTILS}
        python {input.script} --data "{input.data}" \
                              --output "{output.data}" \
                              --output_img "{output.img}" \
                              --alpha {params.alpha} \
                              --max_Niter {params.max_Niter} \
                              --convergence_limit {params.convergence_limit} \
                              --gaussian_sigma {params.gaussian_sigma} \
                              --derivative_filter {params.derivative_filter}
        """


rule critical_points:
    input:
        data = input_file,
        script = os.path.join('scripts', 'critical_points.py'),
        plot_script = os.path.join('scripts', 'plot_critical_points.py')
    params:
        plot_frame = 0,
        skip_step = 3



    output:
        data = os.path.join('{dir}', 'critical_points',
                            '{rule_name}.'+NEO_FORMAT),
        img = report(os.path.join('{dir}', '{rule_name}',
                                  'critical_points.'+PLOT_FORMAT)),
    shell:
        """
        {ADD_UTILS}
        python {input.script} --data "{input.data}" \
                              --output "{output.data}"
        python {input.plot_script} --data "{output.data}" \
                                   --output "{output.img}" \
                                   --frame_id {params.plot_frame} \
                                   --skip_step {params.skip_step}
        """


rule critical_points_clustering:
    # ToDo
    input:
        data = input_file,
    output:
        data = os.path.join('{dir}', 'critical_points_clustering',
                            '{rule_name}.'+NEO_FORMAT),
    shell:
        """
        {ADD_UTILS}
        cp {input.data} {output.data}
        """




def vector_field_data(wildcards):
    if DETECT_CRITICAL_POINTS:
        return  os.path.join('{dir}', 'critical_points_clustering',
                            '{rule_name}.'+NEO_FORMAT),
    else:
        return  os.path.join('{dir}', 'optical_flow',
                            '{rule_name}.'+NEO_FORMAT),

rule merge_wave_definitions:
    input:
        trigger_data =  os.path.join('{dir}', 'clustering',
                            '{rule_name}.'+NEO_FORMAT),
        node_data = vector_field_data,
        script = os.path.join('scripts', 'merge_wave_definitions.py')
    output:
        data = os.path.join('{dir}', 'merge_wave_definitions', '{rule_name}.'+NEO_FORMAT)
    shell:
        """
        {ADD_UTILS}
        python {input.script} --trigger_data "{input.trigger_data}" \
                              --node_data "{input.node_data}" \
                              --output "{output.data}"
        """








